#!/bin/env python                                                                                                                                                              
# Author: Brett Savoie (brettsavoie@gmail.com)
import sys,argparse,os,ast,re,fnmatch,subprocess
from numpy import *

def main(argv):

    parser = argparse.ArgumentParser(description='Average over all files matching the -f string.')

    #optional arguments                                                                                                                                                        
    parser.add_argument('-f', dest='Filename', default='*.in.init',
                        help = 'The program operates on all input files discovered during a directory walk from the working directory whose name matches this variable. '\
                               'For example, if the user supplies *.in, then all files ending in .in within all subfolders relative the working directory will be submitted. '\
                               'Note that the program uses python''s regular expression matching for finding files, so ''*'' can be used as a wildcard character '\
                               'or as a literal by using the ''\\'' as an escape character. When basic wildcards are used, the program will submit all input files matching '\
                               'the wildcard pattern as separate jobs. (default: *in.init)') 

    parser.add_argument('-d', dest='path', default=None,
                        help = 'The program operates on all files discovered during a directory walk that match the -f argument. Optionally, a directory name or any string can also be supplied via this '+\
                               'argument and only files matching -f whose directory string includes -d will be operated on. (default: "")')

    parser.add_argument('-p', dest='procs', default=1,
                        help = 'Specifies the number of processors for each job (default: 1; max 8)')
                        
    parser.add_argument('-o', dest='outputname', default="lammps_mass",
                        help = 'Specifies the job name (default: orca_mass)')

    parser.add_argument('-t', dest='walltime', default=4,
                        help = 'Specifies the walltime for each job (default: 48, hours by default, if Xmin is used then the argument will be interpretted in minutes)')

    parser.add_argument('-q', dest='queue', default='standby',
                        help = 'Specifies the queue for the job (default: regular; valid options are cluster dependent.')

    parser.add_argument('-npp', dest='N_part', default=1,
                        help = 'Specifies the number of input files to bundle per lammps exe call (*N*umber of jobs *P*er lammps *P*artition. bundled input files and lammps '+\
                               'partitions in the exe call are automatically generated by this '+\
                               'script. Using partitions avoids making a large number of executable call on the cluster.')                               

    parser.add_argument('-ngpu', dest='ngpu', default=1,
                        help = 'Specifies the number gpus to use per job (default: 1)')

    parser.add_argument('-ppn', dest='ppn', default=20,
                        help = 'Specifies the number of processors per node on the cluster architecture. the -ppn %% -p should equal zero. (default: 24)') 

    parser.add_argument('-size', dest='size', default=100000,
                        help = 'Specifies the number of calculations to bundle per submitted job (default: 100000)')

    parser.add_argument('-sched', dest='sched', default='torque-halstead',
                        help = 'Specifies the scheduler protocol to use (torque-halstead and torque-titan are implemented)')

    parser.add_argument('-a', dest='account', default=None,
                        help = 'Account to charge the job to. Usually only necessary on government machines. (default: None)')

    parser.add_argument('-gpu_split', dest='gpu_split', default=-1,
                        help = 'LAMMPS gpu option (only matters when using a scheduler with gpu bundling routines) that controls the fraction of atoms offloaded onto the gpu. '+\
                               '-1 equals dynamic loading (default but incompatible with hybrid pair styles), float between 0.0-1.0 specifies the fraction on gpu directly (default: -1)')

    parser.add_argument('-gpu_neigh', dest='gpu_neigh', default=1,
                        help = 'LAMMPS gpu option (only matters when using a scheduler with gpu bundling routines) that controls whether the neighbor lists are built on the cpus or gpus. '+\
                               '1 equals build on gpus, 0 equals build on cpus (default: 1)')

    parser.add_argument('--overwrite', dest='overwrite', default=0, action='store_const', const=1,
                        help = 'When set, if previous run data is discovered in the submission folders it is deleted. (default: off)')

    parser.add_argument('--no_gpu', dest='no_gpu', default=0, action='store_const', const=1,
                        help = 'OBSOLETE, only used with older schedulers. When set, the jobs will run only on cpus. (default: off)')

    parser.add_argument('--gpu', dest='gpu_flag', default=False, action='store_const', const=True,
                        help = 'When set, the jobs will use gpus. (default: off)')

    parser.add_argument('--silent', dest='verbose', default=1, action='store_const', const=0,
                        help = 'When set, no output will be printed from the script (default: off)')

    parser.add_argument('-path_to_exe',dest='path_to_exe', default="/depot/bsavoie/apps/lammps/exe/lmp_mpi_180501",
                        help = 'location of the lammps exe including absolute path (e.g. /ccs/proj/chm114/lammps-7Dec15/exe/lmp_titan_gpu)')

    parser.add_argument('-path_to_mpi',dest='path_to_mpi', default=None, 
                        help = 'location of the mpi folder that the lammps exe was compiled against. (e.g. /depot/bsavoie/apps/openmpi/1.8.8)')

    parser.add_argument('-shell',dest='shell', default="",
                        help = 'Additional shell commands to be placed before the executable call (e.g., "module load lammps")')

    args=parser.parse_args()
    if type(args.walltime) == str and "min" in args.walltime: args.walltime = int(args.walltime.split('min')[0]); min_flag = 1
    else: args.walltime = int(args.walltime); min_flag = 0
    args.procs = int(args.procs)
    args.ppn = int(args.ppn)
    args.size = int(args.size)
    args.N_part = int(args.N_part)
    Filename = args.Filename
    working_dir = os.getcwd()
    args.gpu_split = float(args.gpu_split)
    args.gpu_neigh = int(args.gpu_neigh)
    if args.gpu_split < -1 or args.gpu_split > 1.0: print("ERROR: -gpu_split must be a float between -1 and 1. Exiting..."); quit()
    if args.gpu_neigh not in [0,1]: print("ERROR: -gpu_neigh only accepts 0 and 1 as arguments. Exiting..."); quit()
    if args.N_part > 1: args.size = args.N_part
    if args.path_to_mpi is not None:
        if args.path_to_mpi[-1] == "/":
            args.path_to_mpi = args.path_to_mpi[:-1]


    # Check that the number of processors per job divides into the number of processors per node.
#    if args.ppn % args.procs != 0:
#        print "\nERROR: the -ppn % -p must be zero to ensure that jobs aren't split across nodes. Exiting...\n"
#        quit()
    if args.size > 1 and args.N_part > 1 and  args.procs*args.N_part % args.ppn != 0:
        if args.sched != "slurm-tachus":
            print("\nERROR: the number of processors per partition (args.procs*args.N_part) must be divisible")
            print("       by the number of processors per node (-ppn) to ensure that lammps execution calls")
            print("       aren't split across nodes. Exiting...\n")
            quit()

    # Create a dictionary from the filenames, where each dictionary key corresponds to a filename and each entry is a list
    # of subfiles to be processed as a batch. e.g., molecule.in might show up in twenty subfolders. molecule.in would end
    # up as a key, and the list of individual instances of molecule.in would constitute the entry.
    Files = {}
    if args.path == None:
        Files[Filename] = [ os.path.join(dp, f) for dp, dn, filenames in os.walk('.') for f in filenames if fnmatch.fnmatch(f,Filename) ]
    else:
        args.path = args.path.split()
        Files[Filename] = [ os.path.join(dp, f) for dp, dn, filenames in os.walk('.') for f in filenames if (fnmatch.fnmatch(f,Filename) and False not in [ i in dp for i in args.path ]) ]
    
    #################################################################
    # Iterate over all discovered input files, cd to the containing #
    # directory and check if the job already has an output file     #
    #################################################################    
    input_files = []
    input_paths = []
    
    for i in list(Files.keys()):

        # Sort the filenames as string
        Current_files = natural_sort(Files[i])

        if args.verbose == 1:
            print("{}".format("#"*80))
            print("# {:^76s} #".format("PROCESSING THE FOLLOWING FILES"))
            print("{}".format("#"*80))
            for j in Current_files:
                print(j)
    
        for j in Current_files:

            # Change to the directory holding the current file
            path_to_file = '/'.join(j.split('/')[0:-1])
            if path_to_file != '':
                os.chdir(path_to_file)

            # Save the submission input files and paths to lists
            current_name = j.split('/')[-1]
            if current_name.split('.')[0]+".log" not in os.listdir('.'):
                input_files += [current_name]
                input_paths += [path_to_file]

            elif args.overwrite == 1:
                input_files += [current_name]
                input_paths += [path_to_file]
                                    
            # Skip any that already have output files present
            elif args.verbose == 1:
                print("Skipped file {} because output was already found".format(current_name))
            os.chdir(working_dir)

    # If no viable jobs were discovered then quit
    if len(input_files) == 0:
        print("No jobs in need of running, exiting...")
        quit()

    # Insert escape characters for ( and )
    for i in [ "(", ")" ]:
        input_files = [ _.replace(i,"\{}".format(i)) for _ in input_files ]
        input_paths = [ _.replace(i,"\{}".format(i)) for _ in input_paths ]

    # Calculate the number of separate jobs to be submitted
    N_bundles = int(ceil(float(len(input_files))/float(args.size)))
    
    # Bundle the jobs
    bundled_files = [[] for i in range(N_bundles) ]
    bundled_paths = [[] for i in range(N_bundles) ]
    for i in range(N_bundles):
        bundled_files[i] = input_files[i*args.size:(i+1)*args.size]
        bundled_paths[i] = input_paths[i*args.size:(i+1)*args.size]    

    # Create input files and submit each bundle
    for n in range(len(bundled_files)):
        
        # Set input_files and input_paths to point towards the bundled_files and bundled_paths sublists
        # NOTE: the reuse of variable names (input_files, input_paths) is just a convenience since the following loops weren't written for the bundled feature.
        input_files = bundled_files[n]
        input_paths = bundled_paths[n]

        # If partitions are being used, then the discovered input files are bundled into output_name.part.* files that are run on lammps partitions
        # The following loops holds a list of tuples, each tuple has one of the generated partition files and the number of paritions is should run on. 
        if args.N_part > 1 or args.gpu_flag is True:
            partition_names = []
            for i in range(int(ceil(float(len(input_files))/float(args.N_part)))):
                tmp_files = input_files[i*args.N_part:(i+1)*args.N_part]
                tmp_paths = input_paths[i*args.N_part:(i+1)*args.N_part]
                partition_names.append((bundle_jobs([ tmp_paths[count_j]+'/'+j for count_j,j in enumerate(tmp_files) ],output_name='{}.bundle.{}.part.{}'.format(args.outputname,n,i),\
                                                    neigh_on_gpu=args.gpu_neigh,split_factor=args.gpu_split,gpu_flag = args.gpu_flag),len(tmp_files)))
        
        # Initialize working variable for the number of sub jobs being submitted, total cores, total nodes, and jobs per node
        N_jobs = len(input_files)
        N_cores = N_jobs*args.procs
        N_nodes = int(ceil(float(N_cores)/float(args.ppn)))
        N_jpn   = int(args.ppn/args.procs)

        # Generic slurm submission
        if args.sched == "slurm-halstead":

            # Write commands for the running the current job
            with open('{}.{}.submit'.format(args.outputname,n),'w') as f:
                f.write("#!/bin/bash\n")
                f.write("#\n")
                f.write("#SBATCH --job-name {}.{}\n".format(args.outputname,n))
                f.write("#SBATCH -o {}.{}.out\n".format(args.outputname,n))
                f.write("#SBATCH -e {}.{}.err\n".format(args.outputname,n))
                f.write("#SBATCH -A {}\n".format(args.queue))
                f.write("#SBATCH -N {}\n".format(int(N_nodes))) # should be N_nodes//N_job , but here the N_job is always set to 1 in our config.txt file, so doesn't matter
                if args.procs < args.ppn:
                    #f.write("#SBATCH --ntasks-per-node={}\n".format(args.procs))
                    f.write("#SBATCH -n {}\n".format(N_nodes*args.procs))
                else:
                    #f.write("#SBATCH --ntasks-per-node={}\n".format(args.ppn))
                    f.write("#SBATCH -n {}\n".format(N_nodes*args.ppn))
                if min_flag == 0:
                    f.write("#SBATCH -t {}:00:00\n".format(args.walltime))
                elif min_flag == 1:
                    f.write("#SBATCH -t 00:{}:00\n".format(args.walltime))
                #if args.account is not None:
                #    f.write("#SBATCH -A {}\n".format(args.account))
                if args.path_to_mpi is None:
                    args.path_to_mpi = "/home/bsavoie/apps/openmpi/3.0.1"
                if args.gpu_flag is True:
                    f.write("#SBATCH --gres=gpu:{}\n".format(args.ngpu))
                f.write("\n# Prepend MPI path\n")
                f.write('#export PATH="{}/bin:$PATH"\n'.format(args.path_to_mpi))
                f.write('#export LD_LIBRARY_PATH="{}/lib:$LD_LIBRARY_PATH"\n\n'.format(args.path_to_mpi))
                #XXX for bell, there seems to be some mpi issue
                f.write("module load gcc/9.3.0 \n")  
                f.write("module load openmpi/3.1.4 \n") 
                f.write("module load ffmpeg/4.2.2  \n")
                f.write("module load  openblas/0.3.8  \n")
                f.write("module load  gsl/2.4  \n\n")
                #XXX

                f.write("# Write out some information on the job\n")
                f.write('echo Running on hosts: $SLURM_NODELIST\n')
                f.write('echo Running on $SLURM_NNODES nodes.\n')
                f.write('echo "Running on \$SLURM_NPROCS processors."\n')
                f.write('echo "Current working directory is `pwd`"\n')
                f.write('echo "Copying input file to scratch..."\n\n')
                
                # Add shell commands                
                f.write('# USER SUPPLIED SHELL COMMANDS\n{}\n'.format(args.shell))

                # If no partitions are being used then the following loop generates the job execution commands
                if args.N_part == 1 or args.gpu_flag is True:

                    # For gpu jobs on one partition the jobs must be bundled.
                    if args.gpu_flag is True:
                        input_paths = [ '/'.join(os.path.abspath(_[0]).split('/')[:-1]) for _ in partition_names ]
                        input_files = [ os.path.abspath(_[0]).split('/')[-1] for _ in partition_names ]

                    # executable calls
                    for count_j,j in enumerate(input_paths):
                        f.write("cd {}\n".format(j))
                        if args.gpu_flag is True:
                            f.write("mpirun -np {} {} -suffix gpu -in {} >> {} &\n".format(args.procs,args.path_to_exe,input_files[count_j],'.'.join([ k for k in input_files[count_j].split('.')[:-1] ])+'.out'))
                        else:
                            f.write("mpirun -np {} {} -in {} >> {} &\n".format(args.procs,args.path_to_exe,input_files[count_j],'.'.join([ k for k in input_files[count_j].split('.')[:-1] ])+'.out'))

                        f.write("cd {}\n\n".format(working_dir))

                # If partitions are being used then the following loop generates the job execution commands
                if args.N_part > 1:

                    # executable calls
                    for count_j,j in enumerate(partition_names):
                        f.write("echo -e 'Running {}'\n".format(j[0]))
                        if args.gpu_flag is True:
                            f.write("mpirun -np {} {} -suffix gpu -pscreen none -plog none -log none -partition {}x{} -in {} &\n".format(args.procs*j[1],args.path_to_exe,j[1],args.procs,j[0]))
                        else:
                            f.write("mpirun -np {} {} -pscreen none -plog none -log none -partition {}x{} -in {} &\n".format(args.procs*j[1],args.path_to_exe,j[1],args.procs,j[0]))

                f.write("wait\n")


            subprocess.call("chmod 777 {}.{}.submit".format(args.outputname,n), shell=True)
            subprocess.call("sbatch {}.{}.submit".format(args.outputname,n), shell=True)

        if args.sched == "slurm-negishi":

            # Write commands for the running the current job
            with open('{}.{}.submit'.format(args.outputname,n),'w') as f:
                f.write("#!/bin/bash\n")
                f.write("#\n")
                f.write("#SBATCH --job-name {}.{}\n".format(args.outputname,n))
                f.write("#SBATCH -o {}.{}.out\n".format(args.outputname,n))
                f.write("#SBATCH -e {}.{}.err\n".format(args.outputname,n))
                f.write("#SBATCH -A {}\n".format(args.queue))
                f.write("#SBATCH -N {}\n".format(int(N_nodes))) # should be N_nodes//N_job , but here the N_job is always set to 1 in our config.txt file, so doesn't matter
                if args.procs < args.ppn:
                    #f.write("#SBATCH --ntasks-per-node={}\n".format(args.procs))
                    f.write("#SBATCH -n {}\n".format(N_nodes*args.procs))
                else:
                    #f.write("#SBATCH --ntasks-per-node={}\n".format(args.ppn))
                    f.write("#SBATCH -n {}\n".format(N_nodes*args.ppn))
                if min_flag == 0:
                    f.write("#SBATCH -t {}:00:00\n".format(args.walltime))
                elif min_flag == 1:
                    f.write("#SBATCH -t 00:{}:00\n".format(args.walltime))
                #if args.account is not None:
                #    f.write("#SBATCH -A {}\n".format(args.account))
                if args.path_to_mpi is None:
                    args.path_to_mpi = "/home/bsavoie/apps/openmpi/3.0.1"
                if args.gpu_flag is True:
                    f.write("#SBATCH --gres=gpu:{}\n".format(args.ngpu))
                f.write("\n# Prepend MPI path\n")
                f.write('#export PATH="{}/bin:$PATH"\n'.format(args.path_to_mpi))
                f.write('#export LD_LIBRARY_PATH="{}/lib:$LD_LIBRARY_PATH"\n\n'.format(args.path_to_mpi))
                #XXX for bell, there seems to be some mpi issue
                # for /depot/bsavoie/apps/lammps-29Sep2021/exe/lmp_mpi
                # if using module load then openmpi and gcc are fine
                #f.write("module load intel \n")  
                #f.write("module load impi \n")  
                #XXX

                f.write("# Write out some information on the job\n")
                f.write('echo Running on hosts: $SLURM_NODELIST\n')
                f.write('echo Running on $SLURM_NNODES nodes.\n')
                f.write('echo "Running on \$SLURM_NPROCS processors."\n')
                f.write('echo "Current working directory is `pwd`"\n')
                f.write('echo "Copying input file to scratch..."\n\n')
                
                # Add shell commands                
                f.write('# USER SUPPLIED SHELL COMMANDS\n{}\n'.format(args.shell))

                # If no partitions are being used then the following loop generates the job execution commands
                if args.N_part == 1 or args.gpu_flag is True:

                    # For gpu jobs on one partition the jobs must be bundled.
                    if args.gpu_flag is True:
                        input_paths = [ '/'.join(os.path.abspath(_[0]).split('/')[:-1]) for _ in partition_names ]
                        input_files = [ os.path.abspath(_[0]).split('/')[-1] for _ in partition_names ]

                    # executable calls
                    for count_j,j in enumerate(input_paths):
                        f.write("cd {}\n".format(j))
                        if args.gpu_flag is True:
                            f.write("mpirun -np {} {} -suffix gpu -in {} >> {} &\n".format(args.procs,args.path_to_exe,input_files[count_j],'.'.join([ k for k in input_files[count_j].split('.')[:-1] ])+'.out'))
                        else:
                            f.write("mpirun -np {} {} -in {} >> {} &\n".format(args.procs,args.path_to_exe,input_files[count_j],'.'.join([ k for k in input_files[count_j].split('.')[:-1] ])+'.out'))

                        f.write("cd {}\n\n".format(working_dir))

                # If partitions are being used then the following loop generates the job execution commands
                if args.N_part > 1:

                    # executable calls
                    for count_j,j in enumerate(partition_names):
                        f.write("echo -e 'Running {}'\n".format(j[0]))
                        if args.gpu_flag is True:
                            f.write("mpirun -np {} {} -suffix gpu -pscreen none -plog none -log none -partition {}x{} -in {} &\n".format(args.procs*j[1],args.path_to_exe,j[1],args.procs,j[0]))
                        else:
                            f.write("mpirun -np {} {} -pscreen none -plog none -log none -partition {}x{} -in {} &\n".format(args.procs*j[1],args.path_to_exe,j[1],args.procs,j[0]))

                f.write("wait\n")


            subprocess.call("chmod 777 {}.{}.submit".format(args.outputname,n), shell=True)
            subprocess.call("sbatch {}.{}.submit".format(args.outputname,n), shell=True)
        
        if args.sched == "slurm-comet":

            # Write commands for the running the current job
            with open('{}.{}.submit'.format(args.outputname,n),'w') as f:
                f.write("#!/bin/bash\n")
                f.write("#\n")
                f.write("#SBATCH --job-name {}.{}\n".format(args.outputname,n))
                f.write("#SBATCH -o {}.{}.out\n".format(args.outputname,n))
                f.write("#SBATCH -e {}.{}.err\n".format(args.outputname,n))
                f.write("#SBATCH -p {}\n".format(args.queue))
                f.write("#SBATCH --nodes={}\n".format(int(N_nodes))) # should be N_nodes//N_job , but here the N_job is always set to 1 in our config.txt file, so doesn't matter
                if args.procs < args.ppn:
                    f.write("#SBATCH --ntasks-per-node={}\n".format(args.procs))
                    #f.write("#SBATCH -n {}\n".format(N_nodes*args.procs))
                else:
                    f.write("#SBATCH --ntasks-per-node={}\n".format(args.ppn))
                    #f.write("#SBATCH -n {}\n".format(N_nodes*args.ppn))
                if min_flag == 0:
                    f.write("#SBATCH -t {}:00:00\n".format(args.walltime))
                elif min_flag == 1:
                    f.write("#SBATCH -t 00:{}:00\n".format(args.walltime))
                if args.account is not None:
                    f.write("#SBATCH -A {}\n".format(args.account))
                if args.path_to_mpi is None:
                    #args.path_to_mpi = "/opt/openmpi/intel/ib" # default openmpi module for comet
                    args.path_to_mpi = "/home/seo89/libs/openmpi"
                if args.gpu_flag is True:
                    f.write("#SBATCH --gres=gpu:{}\n".format(args.ngpu))
                f.write("\n# Prepend MPI path\n")
                f.write('#export PATH="{}/bin:$PATH"\n'.format(args.path_to_mpi))
                f.write('#export LD_LIBRARY_PATH="{}/lib:$LD_LIBRARY_PATH"\n\n'.format(args.path_to_mpi))
                #f.write("module load openmpi_ib/3.1.4\n\n")
                f.write("export OMP_NUM_THREADS={}".format(int(args.ppn)))

                f.write("# Write out some information on the job\n")
                f.write('echo Running on hosts: $SLURM_NODELIST\n')
                f.write('echo Running on $SLURM_NNODES nodes.\n')
                f.write('echo "Running on \$SLURM_NPROCS processors."\n')
                f.write('echo "Current working directory is `pwd`"\n')
                f.write('echo "Copying input file to scratch..."\n\n')
                
                # Add shell commands                
                f.write('# USER SUPPLIED SHELL COMMANDS\n{}\n'.format(args.shell))

                # If no partitions are being used then the following loop generates the job execution commands
                if args.N_part == 1 or args.gpu_flag is True:

                    # For gpu jobs on one partition the jobs must be bundled.
                    if args.gpu_flag is True:
                        input_paths = [ '/'.join(os.path.abspath(_[0]).split('/')[:-1]) for _ in partition_names ]
                        input_files = [ os.path.abspath(_[0]).split('/')[-1] for _ in partition_names ]

                    # executable calls
                    for count_j,j in enumerate(input_paths):
                        f.write("cd {}\n".format(j))
                        if args.gpu_flag is True:
                            f.write("mpirun -np {} {} -suffix gpu -in {} >> {} &\n".format(args.procs,args.path_to_exe,input_files[count_j],'.'.join([ k for k in input_files[count_j].split('.')[:-1] ])+'.out'))
                        else:
                            f.write("mpirun -np {} {} -in {} >> {} &\n".format(args.procs,args.path_to_exe,input_files[count_j],'.'.join([ k for k in input_files[count_j].split('.')[:-1] ])+'.out'))

                        f.write("cd {}\n\n".format(working_dir))

                # If partitions are being used then the following loop generates the job execution commands
                if args.N_part > 1:

                    # executable calls
                    for count_j,j in enumerate(partition_names):
                        f.write("echo -e 'Running {}'\n".format(j[0]))
                        if args.gpu_flag is True:
                            f.write("mpirun -np {} {} -suffix gpu -pscreen none -plog none -log none -partition {}x{} -in {} &\n".format(args.procs*j[1],args.path_to_exe,j[1],args.procs,j[0]))
                        else:
                            f.write("mpirun -np {} {} -pscreen none -plog none -log none -partition {}x{} -in {} &\n".format(args.procs*j[1],args.path_to_exe,j[1],args.procs,j[0]))

                f.write("wait\n")


            subprocess.call("chmod 777 {}.{}.submit".format(args.outputname,n), shell=True)
            subprocess.call("sbatch {}.{}.submit".format(args.outputname,n), shell=True)

        # Submission on ORNL titan
        if args.sched == "slurm-gpu":

            # Begin making input files for the bundled submission
            with open('{}.{}.submit'.format(args.outputname,n),'w') as f:

                f.write("#PBS -N {}.{}\n".format(args.outputname,n))
                f.write("#PBS -A chm114\n")
                f.write("#PBS -l nodes={}\n".format(N_nodes))
                if min_flag == 0:
                    f.write("#PBS -l walltime={}:00:00\n".format(args.walltime))
                elif min_flag == 1:
                    f.write("#PBS -l walltime=00:{}:00\n".format(args.walltime))
                if args.queue == 'debug':
                    f.write("#PBS -q debug\n")
                f.write("#PBS -S /bin/sh\n")
                f.write("#PBS -o {}.out\n".format(args.outputname))
                f.write("#PBS -e {}.err\n\n".format(args.outputname))

                f.write("# LOAD MODULES\n")
                f.write("module unload PrgEnv-pgi\n")
                f.write("module load PrgEnv-gnu\n")
                f.write("module load fftw\n")
                f.write("module load cudatoolkit\n")
                f.write("module load lammps\n")
                f.write("export CRAY_CUDA_PROXY=1\n\n")

                f.write("# cd into the submission directory\n")
                f.write("cd {}\n".format(working_dir))
                f.write("echo Working directory is ${}\n".format(working_dir))
                f.write("echo Running on host `hostname`\n")
                f.write("echo Time is `date`\n\n")

                f.write('# Start submitting jobs\n')
                # If no partitions are being used then the following loop generates the job execution commands
                if args.N_part == 1:

                    # aprun-based submission
                    for count_j,j in enumerate(input_paths):
                        f.write("cd {}\n".format(j))
                        if args.no_gpu == 1:
                            f.write("aprun -n {} {} -in {} >> {} &\n".format(args.procs,args.path_to_exe,\
                                                                                         input_files[count_j],'.'.join([ k for k in input_files[count_j].split('.')[:-1] ])+'.out'))                        
                        else:
                            f.write("aprun -n {} {} -suffix gpu -in {} >> {} &\n".format(args.procs,args.path_to_exe,\
                                                                                         input_files[count_j],'.'.join([ k for k in input_files[count_j].split('.')[:-1] ])+'.out'))                        

                        f.write("cd {}\n\n".format(working_dir))

                # If partitions are being used then the following loop generates the job execution commands
                if args.N_part > 1:

                    # aprun-based submission
                    for count_j,j in enumerate(partition_names):
                        f.write("echo -e 'Running {}'\n".format(j[0]))
                        if args.no_gpu == 1:
                            f.write("aprun -n {} {} -pscreen none -plog none -log none -partition {}x{} -in {} &\n".format(args.procs*j[1],args.path_to_exe,j[1],args.procs,j[0]))
                        else:
                            f.write("aprun -n {} {} -suffix gpu -pscreen none -plog none -log none -partition {}x{} -in {} &\n".format(args.procs*j[1],args.path_to_exe,j[1],args.procs,j[0]))
                f.write("wait\n")

            subprocess.call("chmod 777 {}.{}.submit".format(args.outputname,n), shell=True)
            subprocess.call("qsub {}".format(args.outputname+'.'+str(n)+'.submit'), shell=True)


        # Submission on ORNL titan
        if args.sched == "torque-titan":

            # Begin making input files for the bundled submission
            with open('{}.{}.submit'.format(args.outputname,n),'w') as f:

                f.write("#PBS -N {}.{}\n".format(args.outputname,n))
                f.write("#PBS -A chm114\n")
                f.write("#PBS -l nodes={}\n".format(N_nodes))
                if min_flag == 0:
                    f.write("#PBS -l walltime={}:00:00\n".format(args.walltime))
                elif min_flag == 1:
                    f.write("#PBS -l walltime=00:{}:00\n".format(args.walltime))
                if args.queue == 'debug':
                    f.write("#PBS -q debug\n")
                f.write("#PBS -S /bin/sh\n")
                f.write("#PBS -o {}.out\n".format(args.outputname))
                f.write("#PBS -e {}.err\n\n".format(args.outputname))

                f.write("# LOAD MODULES\n")
                f.write("module unload PrgEnv-pgi\n")
                f.write("module load PrgEnv-gnu\n")
                f.write("module load fftw\n")
                f.write("module load cudatoolkit\n")
                f.write("module load lammps\n")
                f.write("export CRAY_CUDA_PROXY=1\n\n")

                f.write("# cd into the submission directory\n")
                f.write("cd {}\n".format(working_dir))
                f.write("echo Working directory is ${}\n".format(working_dir))
                f.write("echo Running on host `hostname`\n")
                f.write("echo Time is `date`\n\n")

                f.write('# Start submitting jobs\n')
                # If no partitions are being used then the following loop generates the job execution commands
                if args.N_part == 1:

                    # aprun-based submission
                    for count_j,j in enumerate(input_paths):
                        f.write("cd {}\n".format(j))
                        if args.no_gpu == 1:
                            f.write("aprun -n {} {} -in {} >> {} &\n".format(args.procs,args.path_to_exe,\
                                                                                         input_files[count_j],'.'.join([ k for k in input_files[count_j].split('.')[:-1] ])+'.out'))                        
                        else:
                            f.write("aprun -n {} {} -suffix gpu -in {} >> {} &\n".format(args.procs,args.path_to_exe,\
                                                                                         input_files[count_j],'.'.join([ k for k in input_files[count_j].split('.')[:-1] ])+'.out'))                        

                        f.write("cd {}\n\n".format(working_dir))

                # If partitions are being used then the following loop generates the job execution commands
                if args.N_part > 1:

                    # aprun-based submission
                    for count_j,j in enumerate(partition_names):
                        f.write("echo -e 'Running {}'\n".format(j[0]))
                        if args.no_gpu == 1:
                            f.write("aprun -n {} {} -pscreen none -plog none -log none -partition {}x{} -in {} &\n".format(args.procs*j[1],args.path_to_exe,j[1],args.procs,j[0]))
                        else:
                            f.write("aprun -n {} {} -suffix gpu -pscreen none -plog none -log none -partition {}x{} -in {} &\n".format(args.procs*j[1],args.path_to_exe,j[1],args.procs,j[0]))
                f.write("wait\n")

            subprocess.call("chmod 777 {}.{}.submit".format(args.outputname,n), shell=True)
            subprocess.call("qsub {}".format(args.outputname+'.'+str(n)+'.submit'), shell=True)

        # Submission on ORNL rhea
        if args.sched == "torque-rhea":

            # Rhea doesn't have gpus
            args.no_gpu = 1

            # Begin making input files for the bundled submission
            with open('{}.{}.submit'.format(args.outputname,n),'w') as f:

                f.write("#PBS -N {}.{}\n".format(args.outputname,n))
                f.write("#PBS -A chm114\n")
                f.write("#PBS -l nodes={}\n".format(N_nodes))
                if min_flag == 0:
                    f.write("#PBS -l walltime={}:00:00\n".format(args.walltime))
                elif min_flag == 1:
                    f.write("#PBS -l walltime=00:{}:00\n".format(args.walltime))
                if args.queue == 'debug':
                    f.write("#PBS -q debug\n")
                f.write("#PBS -S /bin/sh\n")
                f.write("#PBS -o {}.out\n".format(args.outputname))
                f.write("#PBS -e {}.err\n\n".format(args.outputname))

                f.write("# cd into the submission directory\n")
                f.write("cd {}\n".format(working_dir))
                f.write("echo Working directory is ${}\n".format(working_dir))
                f.write("echo Running on host `hostname`\n")
                f.write("echo Time is `date`\n\n")

                f.write('# Start submitting jobs\n')

                # If no partitions are being used then the following loop generates the job execution commands
                if args.N_part == 1:

                    # executable calls
                    for count_j,j in enumerate(input_paths):
                        f.write("cd {}\n".format(j))
                        f.write("mpirun -np {} {} -in {} >> {} &\n".format(args.procs,args.path_to_exe,input_files[count_j],'.'.join([ k for k in input_files[count_j].split('.')[:-1] ])+'.out'))
                        f.write("cd {}\n\n".format(working_dir))

                # If partitions are being used then the following loop generates the job execution commands
                if args.N_part > 1:

                    # executable calls
                    for count_j,j in enumerate(partition_names):
                        f.write("echo -e 'Running {}'\n".format(j[0]))
                        f.write("mpirun -np {} {} -pscreen none -plog none -log none -partition {}x{} -in {} &\n".format(args.procs*j[1],args.path_to_exe,j[1],args.procs,j[0]))
                f.write("wait\n")

            subprocess.call("chmod 777 {}.{}.submit".format(args.outputname,n), shell=True)
            subprocess.call("qsub {}".format(args.outputname+'.'+str(n)+'.submit'), shell=True)

        # Submission on Purdue halstead
        if args.sched == "torque-halstead":

            # Begin making input files for the bundled submission
            with open('{}.{}.submit'.format(args.outputname,n),'w') as f:

                f.write("#PBS -N {}.{}\n".format(args.outputname,n))
                f.write("#PBS -A chm114\n")
                f.write("#PBS -l nodes={}:ppn={}\n".format(N_nodes,args.ppn))
                if min_flag == 0:
                    f.write("#PBS -l walltime={}:00:00\n".format(args.walltime))
                elif min_flag == 1:
                    f.write("#PBS -l walltime=00:{}:00\n".format(args.walltime))
                f.write("#PBS -q {}\n".format(args.queue))
                f.write("#PBS -S /bin/sh\n")
                f.write("#PBS -o {}.out\n".format(args.outputname))
                f.write("#PBS -e {}.err\n\n".format(args.outputname))

                f.write("# export openmpi path that the lammps exe was compiled against\n")
                f.write("module load gcc &> /dev/null\n")
                f.write("module --force load intel &> /dev/null\n")
                f.write("module --force load impi &> /dev/null\n")
                f.write('#export PATH="/depot/bsavoie/apps/openmpi/1.8.8/bin:$PATH"\n')
                f.write('#export LD_LIBRARY_PATH="/depot/bsavoie/apps/openmpi/1.8.8/lib:$LD_LIBRARY_PATH"\n\n')

                f.write("# cd into the submission directory\n")
                f.write("cd {}\n".format(working_dir))
                f.write("echo Working directory is ${}\n".format(working_dir))
                f.write("echo Running on host `hostname`\n")
                f.write("echo Time is `date`\n\n")

                f.write('# Start submitting jobs\n')

                # If no partitions are being used then the following loop generates the job execution commands
                if args.N_part == 1:

                    # executable calls
                    for count_j,j in enumerate(input_paths):
                        f.write("cd {}\n".format(j))
                        f.write("mpirun -np {} {} -in {} >> {} &\n".format(args.procs,args.path_to_exe,input_files[count_j],'.'.join([ k for k in input_files[count_j].split('.')[:-1] ])+'.out'))
                        f.write("cd {}\n\n".format(working_dir))

                # If partitions are being used then the following loop generates the job execution commands
                if args.N_part > 1:

                    # executable calls
                    for count_j,j in enumerate(partition_names):
                        f.write("echo -e 'Running {}'\n".format(j[0]))
                        f.write("mpirun -np {} {} -pscreen none -plog none -log none -partition {}x{} -in {} &\n".format(args.procs*j[1],args.path_to_exe,j[1],args.procs,j[0]))
                f.write("wait\n")

            subprocess.call("chmod 777 {}.{}.submit".format(args.outputname,n), shell=True)
            subprocess.call("qsub {}".format(args.outputname+'.'+str(n)+'.submit'), shell=True)

        # Submission on Miller group tachus
        if args.sched == "slurm-tachus":

            # tachus doesn't have gpus
            args.no_gpu = 1

            # Create the individual submission files and submit
            current_dir = os.getcwd()
            for count_i,i in enumerate(input_paths):
                os.chdir(i)          
                # base_name = '.'.join([ j for j in input_files[count_i].split('.')[:-1] ])
                base_name = input_files[count_i]

                # Write commands for the running the current job
                with open(base_name+'.submit','w') as f:
                    f.write("#!/bin/bash\n")
                    f.write("#\n")
                    f.write("#SBATCH --job-name={}\n".format(base_name))
                    f.write("#SBATCH --output={}.out\n".format(base_name))
                    f.write("#SBATCH --error={}.err\n".format(base_name))
                    f.write("#SBATCH --partition={}\n".format(args.queue))
                    f.write("#SBATCH --nodes={}\n".format(N_nodes/int(N_jobs)))
                    f.write("#SBATCH --ntasks-per-node={}\n".format(args.procs))
                    if min_flag == 0:
                        f.write("#SBATCH -t {}:00:00\n".format(args.walltime))
                    elif min_flag == 1:
                        f.write("#SBATCH -t 00:{}:00\n".format(args.walltime))

                    f.write("\n# Load MPI module\n")
                    f.write("module load mpi/openmpi/1.8.1/gcc44\n\n")

                    f.write("# Write out some information on the job\n")
                    f.write('echo Running on hosts: $SLURM_NODELIST\n')
                    f.write('echo Running on $SLURM_NNODES nodes.\n')
                    f.write('echo "Running on \$SLURM_NPROCS processors."\n')
                    f.write('echo "Current working directory is `pwd`"\n')
                    f.write('echo "Copying input file to scratch..."\n\n')

                    f.write("# Run simulation\n")
                    f.write("mpirun -np {} {} -in {}\n\n".format(args.procs,args.path_to_exe,input_files[count_i]))

                subprocess.call("chmod 777 {}.submit".format(base_name), shell=True)
                subprocess.call("sbatch {}.submit".format(base_name), shell=True)
                os.chdir(current_dir)

        # Submission on NERSC edison
        if args.sched == "torque-edison":

            # Begin making input files for the bundled submission
            with open('{}.{}.submit'.format(args.outputname,n),'w') as f:
                f.write("#PBS -q {}\n".format(args.queue))
                f.write("#PBS -l mppwidth={}\n".format(N_cores))
                if min_flag == 0:
                    f.write("#PBS -l walltime={}:00:00\n".format(args.walltime))
                elif min_flag == 1:
                    f.write("#PBS -l walltime=00:{}:00\n".format(args.walltime))
                f.write("#PBS -N {}.{}\n".format(args.outputname,n))
                f.write("#PBS -j oe\n\n")
                f.write("# cd into the submission directory\n")
                f.write('cd {}\n\n'.format(working_dir))
                f.write('# Start submitting jobs\n')
                for count_j,j in enumerate(input_paths):
                    f.write("cd {}\n".format(j))
                    f.write("aprun -n {} {} -in {} >> {} &\n".format(args.procs,args.path_to_exe,\
                                                                     input_files[count_j],'.'.join([ k for k in input_files[count_j].split('.')[:-1] ])+'.out'))
                    f.write("cd {}\n\n".format(working_dir))
                f.write("wait\n")

            subprocess.call("chmod 777 {}.{}.submit".format(args.outputname,n), shell=True)
            subprocess.call("qsub {}".format(args.outputname+'.'+str(n)+'.submit'), shell=True)



# Description: The function expects a list of N input file names
#              that will be bundled together into a single job
#              on N partitions."
# Options:
#    output_names: this is an optional list holding the output name for the bundled input file
#    neigh_on_gpu: 1, neighbor lists get built on the gpus (incompatible with hybrid pair styles), 0 neighbor lists get built on cpus.
#    split_factor: the split factor for dynamic balancing of the cpu/gpu workload (<0 means dynamic; 1 mean all on gpu).
#    old: 0 is off (default), 1 calls the gpu package using the outdated force command (older versions of lammps)\n"
#    num_gpu: 0, gpu partitioning is handled by os and gpu commands aren't written to the input file, >0 number of gpus to split the jobs across.
def bundle_jobs(input_files,output_name='bundle',neigh_on_gpu=0,split_factor=-1,num_gpu=1,old_opt=0,gpu_flag=False):

    # Path variables
    Script_Path = os.path.dirname(os.path.abspath(__file__))
    Sub_Path = "/global/homes/b/bsavoie/bin/LAMMPS_scripts"

    if neigh_on_gpu == 1:
        neigh_opt = 'yes'
    else:
        neigh_opt = 'no'

#     # Print diagnostic
#     print "*"*104
#     print "* {:^100s} *".format("Bundling files for a partition run")
#     print "*"*104    
#     print "{:50s} {}".format("bundling the following files:",', '.join(files))

    # Collect paths
    paths=[]
    for i in input_files:
        if len(i.split('/')[:-1]) == 0:
            paths += ['.']
        else:
            paths+=['/'.join(i.split('/')[:-1])]

    # Collect names
    names=[]
    for i in input_files:
         names += [i.split('/')[-1]]

    # Generate the bundled input file
    if old_opt==1:
        with open("{}.in.init".format(output_name),'w') as b:
            b.write("# Bundled input files\n")
            b.write("{:16s} {:15s} {:7s} {}\n".format("variable","input","world",' '.join([ str(i) for i in names ])))
            b.write("{:16s} {:15s} {:7s} {}\n".format("variable","path","world",' '.join([ str(i) for i in paths ])))
            b.write("\n#===========================================================\n")
            b.write("# BUNDLE VARIABLES\n")
            b.write("#===========================================================\n")
#            b.write("{:16s} {:15s} {:7s} {}\n".format("variable","gpuID","world",' '.join([ str(i) for i in range(len(files)) ])))
            if gpu_flag is True:
                b.write("{:16s} {:15s} {:7s} -1\n".format("package","gpu","force"))
            b.write("\n#Move into run folder\n")
            b.write("shell cd ${path}\n")
            b.write("\n#Run job\n")
            b.write("include ${input}\n")
        quit()
    else:
        with open("{}.in.init".format(output_name),'w') as b:
            b.write("# Bundled input files\n")
            b.write("{:16s} {:15s} {:7s} {}\n".format("variable","input","world",' '.join([ str(i) for i in names ])))
            b.write("{:16s} {:15s} {:7s} {}\n".format("variable","path","world",' '.join([ str(i) for i in paths ])))
            b.write("\n#===========================================================\n")
            b.write("# BUNDLE VARIABLES\n")
            b.write("#===========================================================\n")
#            b.write("{:16s} {:15s} {:7s} {}\n".format("variable","gpuID","world",' '.join([ str(i) for i in range(len(files)) ])))
#            b.write("{:16s} {:15s} {:7s} {:7s}".format("package","gpu",str(int(num_gpu)),"gpuID")+" ${gpuID} ${gpuID}"+" neigh {} split {}\n".format(neigh_opt,scale_factor))
            if gpu_flag is True:
                b.write("{:16s} {:15s} {:7s}".format("package","gpu",str(int(num_gpu)))+" neigh {} split {} device kepler\n".format(neigh_opt,split_factor))
            b.write("\n#Move into run folder\n")
            b.write("shell cd ${path}\n")
            b.write("\n#Run job\n")            
            b.write("include ${input}\n")
    return output_name+".in.init"

def natural_sort(l):
    convert = lambda text: int(text) if text.isdigit() else text.lower()
    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]
    return sorted(l, key = alphanum_key)

if __name__ == "__main__":
   main(sys.argv[1:])
